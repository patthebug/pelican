<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>patthebug</title><link href="http://prateeksinghal.com/" rel="alternate"></link><link href="http://prateeksinghal.com/feeds/prateek-singhal.atom.xml" rel="self"></link><id>http://prateeksinghal.com/</id><updated>2014-05-31T10:20:00-07:00</updated><entry><title>Whining about Portuguese 'Vinho Verde' wine</title><link href="http://prateeksinghal.com/whining-about-portuguese-vinho-verde-wine.html" rel="alternate"></link><updated>2014-05-31T10:20:00-07:00</updated><author><name>Prateek Singhal</name></author><id>tag:prateeksinghal.com,2014-05-31:whining-about-portuguese-vinho-verde-wine.html</id><summary type="html">&lt;h3&gt;Whining about Portuguese 'Vinho Verde' wine&lt;/h3&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Using 5 different types of visualizations, I am trying to distinguish between white and red wine with respect to their chemical contents and trying to understand what makes them different. The description about the wine can be found &lt;a href="http://en.wikipedia.org/wiki/Vinho_Verde"&gt;here&lt;/a&gt;.
The five visualizations are:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Bubble plot&lt;/li&gt;
&lt;li&gt;Scatter plot matrix&lt;/li&gt;
&lt;li&gt;Parallel co-ordinates plot&lt;/li&gt;
&lt;li&gt;Heat map&lt;/li&gt;
&lt;li&gt;Stacked bar plot&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In the data for both - white and red wine, there is only one categorical variable available called 'Wine Quality Type' which determines the quality of the wine in question with 3 being the worst and 8 being the best. Rest of the variables are all numeric variables and determine the chemical content of the wine for that sample. &lt;/p&gt;
&lt;h2&gt;Bubble Plot&lt;/h2&gt;
&lt;p&gt;During the development of this visualization, I wanted to present flexibility to the user which is why this plot provides some level of freedom to the user to select the variables for the X, Y axes and also for the size of the bubble. &lt;/p&gt;
&lt;p&gt;The variables on the X axis are placed on a logarithmic scale by default because of high cluttering of the data. In other words, data density was really high due to the presence of too many data points. Log scale helped in spreading the data apart and made for a nicer and more interpretable visualization. &lt;/p&gt;
&lt;p&gt;There is some amount of jitter in the plot which introduces lie factor but prevents overlapping of data points. The data-ink ratio for this visualization is pretty low as most unwanted attributes like tick marks, minor grid lines, gray background etc have been removed. The major grid line's color has also been changed to light grey so that it doesn't attract a lot of viewer's attention. The legend has also been placed on top of the plot so that it doesn't accidentally overlap any of the data point in the visualization. &lt;/p&gt;
&lt;p&gt;This type of plot is pretty effective in showing outliers in the dataset. Outliers in this case could be extreme values with respect to X and Y axes or extreme values with respect to the bubble size. For example - one can see a few outliers when the selected variable for bubble size is 'Chlorides'. One can also try to look for clusters available within the data by looking at different wine qualities, represented by various colors. Though clusters are not very clearly visible in this case, this plot is capable of showing clusters in the data if they are present within the data. &lt;/p&gt;
&lt;p&gt;Depending on the choices made for X, Y axes variables and the variable for bubble size, one can learn different things about the underlying data. Because of this choice, the interpretation from this visualization is completely dependent on the viewer. Each combination of these variables can lead to a different interpretation of clusters or outliers. &lt;/p&gt;
&lt;p&gt;&lt;img alt="IMAGE" src="https://raw.githubusercontent.com/patthebug/pelican/master/content/images/BubblePlot.png" /&gt;&lt;/p&gt;
&lt;h2&gt;Scatter plot matrix&lt;/h2&gt;
&lt;p&gt;A scatter-plot matrix is capable of showing a lot of data on small individual plots at the same time. It provides us a good overall picture of the data. &lt;/p&gt;
&lt;p&gt;Because of the presence of a lot of data on this visualization, it is hard to pin down any kind of trends but it is possible to look at outliers in the data. The diagonals of this visualization also show us the distribution of the variables in question. It can be clearly seen that there are some long tails in the data pointing to a few outliers present in the data. We can also notice that the distribution of 'sulphates', 'pH' etc is almost normal for most wine quality types whereas distribution of 'alcohol' is often bi-modal and skewed depending on specific wine quality types. One can try to look at clusters by filtering the data using the check boxes (explained more in the interactivity section). &lt;/p&gt;
&lt;p&gt;The data density for this visualization is pretty high as there are multiple small plots. The presence of jitter introduces some lie factor. I have tried to keep the data-ink ratio optimal by removing ticks, background, minor grid lines etc. &lt;/p&gt;
&lt;p&gt;The values on the X axis are slightly hard to see. I could have made the height of the plot bigger but it would have meant using a scroll bar in order to visualize the whole plot. Therefore I shied away from doing so and did my best to fill the screen place with the biggest possible plot. The X axis has also been converted to a logarithmic scale in order to prevent too much cluttering (which is happening anyway because the size of the individual plots forming the whole visualization are so small, cluttering would have been worse without the log scale). &lt;/p&gt;
&lt;p&gt;The axes labels are cut abruptly on the right hand side of the plot. Increasing the height of the plot would have solved this problem as well but because these labels are displayed clearly on top of the plot, it's not much of a problem as the viewer can easily relate to the names of these variables (by referring to the labels on top). &lt;/p&gt;
&lt;p&gt;&lt;img alt="IMAGE" src="https://github.com/patthebug/pelican/blob/master/content/images/ScatterPlotMatrix.PNG" /&gt;&lt;/p&gt;
&lt;h2&gt;Parallel co-ordinates plot&lt;/h2&gt;
&lt;p&gt;This type of plot is very useful in visualizing clusters, outliers and the overall spread of the data with respect to individual variables. &lt;/p&gt;
&lt;p&gt;It can be clearly seen from the visualization that the number of observations for certain wine quality types are few where as they are much more for some of the others. One can also see clearly that variables like 'density', 'free sulphur dioxide' and 'residual sugar' are limited in their ranges where as variables like 'alcohol', 'pH' and 'sulphates' are well spread out. It is also very easy to look at what are some of the outliers in the data and what wine quality type does it belong to. We can notice a major outlier which has an extremely high value of density, another outlier has a high residual sugar value etc. &lt;/p&gt;
&lt;p&gt;One can also make use of the filtering that I have implemented (explained in the interactivity section) to look at different wine quality types to make inferences about them. This plot also works very well as it shows the minimum and maximum values for each of the variables present in the dataset which gives a fair idea about the range of variables to the viewer. &lt;/p&gt;
&lt;p&gt;The lie factor for this plot is minimal as there is no jitter, the data is being displayed as is. The data-ink ratio is optimal as well because nothing unwanted is being displayed on the plot. Data density on the other hand is slightly high because of the number of data points displayed but one can filter on the wine quality type which will reduce the data density to an extent. &lt;/p&gt;
&lt;p&gt;&lt;img alt="IMAGE" src="https://github.com/patthebug/pelican/blob/master/content/images/ParallelPlot.PNG" /&gt;&lt;/p&gt;
&lt;h2&gt;Heat Map&lt;/h2&gt;
&lt;p&gt;This plot is extremely useful in comparing various wine quality types against each other. It shows the viewer an overall spread/range of the values associated with a variable across all wine quality types. &lt;/p&gt;
&lt;p&gt;Depending on the X axis variable chosen from the UI, one can easily distinguish between the spreads of values across different wine quality types. This visualization is also good at pin pointing outliers in the data. For example, when the X axis variable is 'chlorides' and the wine type is 'red', we can clearly see an outlier which has a very high chloride value and belongs to quality type 4. One can also notice that the spread in quality type 8 is not a lot. Once the X axis variable is changed to 'residual sugar', it is easy to see a few outliers (long tails) for wine quality type 6. The interactivity enables the viewer to draw their own inferences for different variables.&lt;/p&gt;
&lt;p&gt;The color scheme used for this visualization is diverging as it presents a nice contrast between high and low values to the user. I have chosen light blue color for the intermediate values which nicely distinguishes between green (for low values) and purple (for high values) and is very easy on the eyes. &lt;/p&gt;
&lt;p&gt;This visualization preserves a good data-ink ratio as nothing unwanted is being displayed. Data density and lie factor for this plot can be argued about slightly. This plot does not do a very good job at giving the user an idea about how many cases are being displayed which introduces some lie factor. For example - a wine quality type with a very narrow range may be displaying many cases at the same time without the viewer even realising the number of cases being displayed. &lt;/p&gt;
&lt;p&gt;&lt;img alt="IMAGE" src="https://github.com/patthebug/pelican/blob/master/content/images/HeatMap.PNG" /&gt;&lt;/p&gt;
&lt;h2&gt;Stacked Bar Plot&lt;/h2&gt;
&lt;p&gt;Heat map did not do a good job in giving an intuition about the number of cases present in each wine quality type, which is why I created a stacked bar plot which gives an idea about the number of cases in each wine quality type. It is still difficult to see the exact number of cases but the viewer can now get an approximate idea regarding the number of cases. &lt;/p&gt;
&lt;p&gt;The user again has the flexibility to look at individual wine types (white and red) or look at them together in which case the plots are displayed at the same time, on top of each other. The legend for the plot has been placed on top of the plot so that it doesn't obstruct the actual visualization. &lt;/p&gt;
&lt;p&gt;The range for X axis has been made the same both the plots when the viewer wants to see 'both' the wine types together for a fair comparison. Not having the same range on the X axis would have introduced some lie factor during comparison. As of now, the lie factor for this visualization is pretty low and the data ink ratio is optimal as nothing unwanted is being displayed on the plot. &lt;/p&gt;
&lt;p&gt;One can notice from the plot that there are not a lot of cases belonging to wine quality type 3 and 8, where as wine quality type 5 and 6 dominate as far as number of cases goes. The user can make use of the interactivity here and choose only the wine quality types that they want to visualize. Clicking on check boxes displays only the selected wine quality types. By default, all wine quality types are displayed when none of the check boxes is selected. This visualization is also good at displaying the distribution of cases across quality types and also identifying outliers.&lt;/p&gt;
&lt;p&gt;&lt;img alt="IMAGE" src="https://github.com/patthebug/pelican/blob/master/content/images/StackedBarPlot.PNG" /&gt;&lt;/p&gt;
&lt;h2&gt;Interactivity&lt;/h2&gt;
&lt;p&gt;The dataset contains values for two different wine types - white and red. I have included a drop down which may be used to visualize white wine v/s red wine at any point for any of the visualizations. There is also an option to visualize both wine types at the same time and it works only for the bubble plot. When this option is selected, bubble plots for both, white and red wine are shown next to each other where comparisons can be done and inferences can be made. I have not implemented this functionality for the rest of the plots as the visualizations become too cluttered and hard to look at when viewed together. &lt;/p&gt;
&lt;p&gt;There is flexibility for the user to select variables that they want to visualize on the X and Y axes. These drop down work for the bubble plot. The drop down for X axis variable also works for the 'Heat Map'. 'Scatter plot matrix' and 'Parallel co-ordinates plot' are showing all the variables at the same time which is why they don't need this functionality. The user also has the flexibility to choose the variable for for bubble size and this works only for the bubble plot. &lt;/p&gt;
&lt;p&gt;I have also included check boxes for various wine quality types which the user may want to visualize separately for purposes of comparison. This functionality works very well across bubble plot, scatter plot matrix, parallel co-ordinates plot and stacked bar plot. Parallel co-ordinates plot wants at least two wine quality types to be selected as it does not work with only one group by default. When none of the check boxes is selected, all wine quality types are displayed by default. This technique has not been applied to the heat map because all wine quality types are already shown on a single plots in different rows, so each type is completely separate already. Filtering may be useful when the viewer feels that there are too many data points to look at or when they want to compare specific types at the same time (say 4 and 7). Color consistency has also been maintained across different visualizations.&lt;/p&gt;
&lt;p&gt;I am trying to display about 5000 cases for white wine and close to 1800 cases for red wine. This can lead to dense plots which is why the use of 'alpha' is inevitable. I wanted to provide enough flexibility to the user to be able to change alpha as per their comfort. Some people may like higher values of alpha while other may not. This is the primary reason I still have this functionality in my visualization despite criticism and people suggesting me to take this functionality out during prototype presentations. For example - if a user wants to compare only two wine quality types on the bubble plot, they may use higher values of alpha whereas if they want to visualize many types at the same type, lower alpha value may be preferred. &lt;/p&gt;
&lt;p&gt;The interactive app has been placed &lt;a href="https://patthebug.shinyapps.io/FinalProject/"&gt;here&lt;/a&gt;. One can play around with the interactivity and the take-home from this dataset may vary from person to person. &lt;/p&gt;
&lt;p&gt;The dataset itself may be found &lt;a href="https://archive.ics.uci.edu/ml/datasets/Wine+Quality"&gt;here&lt;/a&gt;.&lt;/p&gt;</summary><category term="pelican"></category><category term="DataVisualization"></category><category term="shiny"></category></entry><entry><title>Multiprocessing using python</title><link href="http://prateeksinghal.com/multiprocessing-using-python.html" rel="alternate"></link><updated>2014-05-27T10:20:00-07:00</updated><author><name>Prateek Singhal</name></author><id>tag:prateeksinghal.com,2014-05-27:multiprocessing-using-python.html</id><summary type="html">&lt;h3&gt;Simple Linear Regression using Python Multiprocessing library&lt;/h3&gt;
&lt;p&gt;I recently learned executing "Simple Linear Regression" using &lt;code&gt;multiprocessing&lt;/code&gt; module in python. This module is used for parallel processing in python. The &lt;code&gt;β&lt;/code&gt; for Simple Linear Regression is calculated using the following formula:&lt;/p&gt;
&lt;p&gt;$\beta  = \frac {\sum_{i=1}^{n} x_{i}y_{i} -  \frac {1}{n} \sum_{i=1}^{n} x_{i} \sum_{j=1}^{n} y_{j}} {\sum_{i=1}^{n} x_{i}^{2} - \frac {1}{n}(\sum_{i=1}^{n} x_{i})^2}$&lt;/p&gt;
&lt;p&gt;I will use the &lt;code&gt;multiprocessing&lt;/code&gt; and &lt;code&gt;numpy&lt;/code&gt; modules for this task.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt; &lt;span class="n"&gt;as&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;
&lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;multiprocessing&lt;/span&gt; &lt;span class="n"&gt;as&lt;/span&gt; &lt;span class="n"&gt;mp&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The dataset that I will be using for this task is freely downloadable from &lt;a href="ftp://ftp.cdc.gov/pub/Health_Statistics/NCHS/nhanes/nhanes3/1A/adult.dat"&gt;here&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;I will regress &lt;code&gt;age&lt;/code&gt; against &lt;code&gt;weight&lt;/code&gt;. The following function may be used to read the file in:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;def&lt;/span&gt; &lt;span class="n"&gt;map_func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;age&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="mi"&gt;18&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;19&lt;/span&gt;
    &lt;span class="n"&gt;wtlbs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1950&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;1953&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="mi"&gt;1951&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1953&lt;/span&gt; &lt;span class="n"&gt;wt&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;lbs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;self&lt;/span&gt; &lt;span class="n"&gt;reported&lt;/span&gt; &lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="mi"&gt;888&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt; &lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="mi"&gt;999&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;age&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;wtlbs&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I am going to use this function to read the file in parallel using 3 processes at the same time. I am using a quad-core machine which is why I have left 1 process untouched, for recovery purposes just in case I happen to write an infinite loop.&lt;/p&gt;
&lt;p&gt;For achieving this, I will use the &lt;code&gt;Pool&lt;/code&gt; function and initiate 3 processes. After creating these processes, I will use the &lt;code&gt;map&lt;/code&gt; function to distribute the reading job amongst the 3 processes. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;pool&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Pool&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;processes&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;adult&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dat&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;map_func&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The data has some observations in which the weight was unknown or not disclosed. Such observations have weight values of 888 and 999 and the following code will get rid of these observations.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;888&lt;/span&gt; &lt;span class="n"&gt;or&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;999&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;offset&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;offset&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The above code now leaves us with &lt;code&gt;age&lt;/code&gt; and &lt;code&gt;weight&lt;/code&gt; vectors in variables &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; respectively. Let us first up calculate the coefficients for simple linear regression using the conventional method (finding the least squares fit). &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;def&lt;/span&gt; &lt;span class="n"&gt;ols_lls&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;vstack&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))]).&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;
    &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linalg&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lstsq&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;

&lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ols_lls&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;print&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;
&lt;span class="cp"&gt;# should print the values: (-0.0171020631488, 163.871290024)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It may be a good idea now to verify these values with our own implementation of simple linear regression using the formula presented earlier.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;def&lt;/span&gt; &lt;span class="n"&gt;ols_sums&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sum_x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;sum_y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;sum_xx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;sum_xy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kt"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sum_xy&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;sum_x&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;sum_y&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sum_xx&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;power&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sum_x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sum_y&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sum_x&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;n&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;

&lt;span class="n"&gt;print&lt;/span&gt; &lt;span class="n"&gt;pool&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;apply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ols_sums&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="cp"&gt;# should print the values: (-0.017102063148779986, 163.87129002440847)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Notice that I have used two different functions &lt;code&gt;map&lt;/code&gt; and &lt;code&gt;apply&lt;/code&gt; available within the &lt;code&gt;multiprocessing&lt;/code&gt; module. More about these methods can be learnt &lt;a href="https://docs.python.org/dev/library/multiprocessing.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Finally, one can easily notice that the values of parameters using the conventional &lt;code&gt;numpy&lt;/code&gt; method and &lt;code&gt;multiprocessing&lt;/code&gt; module are almost exactly the same.&lt;/p&gt;
&lt;p&gt;Now for finally plotting the results, I will use &lt;code&gt;matplotlib&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;matplotlib&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pyplot&lt;/span&gt; &lt;span class="n"&gt;as&lt;/span&gt; &lt;span class="n"&gt;plt&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="sc"&gt;&amp;#39;o&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Original&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;markersize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;m&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="sc"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;label&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="n"&gt;Fitted&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="err"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The complete code may be found &lt;a href="https://github.com/patthebug/MultiProcessing/blob/master/SimpleLinearRegression.py"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Notice that a performance improvement may not be visible in terms of using 3 processes (multiprocessing) against using just 1 process(least squares fit that we calculated earlier). This is because the data set in this case is not a large dataset. The same example can be repeated on a much larger dataset where the performance improvement will be clearly noticeable. &lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</summary><category term="pelican"></category><category term="simplelinearregression"></category><category term="multiprocessing"></category><category term="python"></category></entry></feed>